{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Multiple Linear Regression\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case\n",
    "\n",
    "We are going to help a company to optimize their advertisement strategy. They spend money on advertisement for different media channels: TV, radio and newspaper - and wants to know which channel is the most most effective.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- suggest marketing plan to increase sales units\n",
    "- use linear regression to predict sales based on different spendings on different marketing channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Initial EDA - Exploratory Data Analysis\n",
    "\n",
    "The dataset for this lecture comes from ISLR - Introduction to Statistical Learning. The dataset used is [Advertising.csv](https://www.kaggle.com/ishaanv/ISLR-Auto)\n",
    "\n",
    "Units:\n",
    "\n",
    "- TV, radio, newspaper - thousands dollars\n",
    "- Sales - thousands units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/advertising.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights via plots**\n",
    "\n",
    " Let's do some scatterplots, one for each feature vs the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = df.shape[1] - 1\n",
    "fig, ax = plt.subplots(1, number_features, figsize=(8, 3), dpi=100)\n",
    "\n",
    "for i, feature in enumerate(df.columns[:-1]):\n",
    "    sns.scatterplot(data=df, x=feature, y=\"Sales\", ax=ax[i])\n",
    "    ax[i].set(xlabel=\"Spending\", title=f\"{feature} spendings\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pairwise relationships in a df\n",
    "ax = sns.pairplot(df, corner=True, height=2)\n",
    "# set corner to True as upper right mirrors the corner, this saves computations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Muliple linear regression\n",
    "\n",
    "As with simple linear regression, multiple linear regression is also supervised learning algorithm - the predicted output is continuous. \n",
    "\n",
    "The difference from linear regression is that we now have several feature (predictor) variables. In the case of 3 features, a multiple linear regression model with one feature variable looks like this:\n",
    "\n",
    "$f_{w,b}(x) = w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3 + b$.\n",
    "\n",
    "We done the output of the model $\\hat{y}$. In other words, we have\n",
    "\n",
    "$\\hat{y}^{i} = w_1 \\cdot x_1^{i} + w_2 \\cdot x_2^{i} + w_3 \\cdot x_3^{i} + b$.\n",
    "\n",
    "The parameters of our model are unknown and needs to be estimated using our training data points $(x^1_1, x^1_2, x^1_3, y^1), (x^2_1, x^2_2, x^2_3, y^2), \\ldots, (x^m_1, x^m_2, x^m_3, y^m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, x_2, x_3 , y = df[\"TV\"].values, df[\"Radio\"].values, df[\"Newspaper\"].values, np.array(df[\"Sales\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index below to see the features and target for training sample i\n",
    "\n",
    "i = 2\n",
    "\n",
    "print(f'Sample {i+1} feature x_1 : {x_1[i]}')\n",
    "print(f'Sample {i+1} feature x_2 : {x_2[i]}')\n",
    "print(f'Sample {i+1} feature x_3 : {x_3[i]}')\n",
    "print(f'Sample {i+1} target  y   : {y[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multiple linear regression\n",
    "\n",
    "We used numpy polyfit to estimate the parameters for a simple linear regression using the the TV-feature alone. However, polyfit only supports one feature. \n",
    "\n",
    "We want to use more than one feature now. In this case three of them (TV, radio, newspaper) and use that to predict sales.\n",
    "\n",
    "One way is to manually solve the **normal equation** or the **closed form equation**: $\\bf{w} = (\\bf{X}^T\\bf{X})^{-1}\\bf{X}^T\\bf{y}$ using linear algebra.\n",
    "\n",
    "\n",
    "$$\\bf{X} = \t\\begin{bmatrix} \n",
    "\t1 & x_1^{1} & x_2^{1}& \\ldots &x_n^{1} \\\\\n",
    "\t1 & x_1^{2} & x_2^{2}& \\ldots &x_n^{2}\\\\\n",
    "\t\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\t1 & x_1^{m}& x_2^{m}& \\ldots &x_n^{m}\n",
    "\\end{bmatrix}, \\bf{y} = \\begin{bmatrix} \n",
    "y^1 \\\\ y^2 \\\\ \\vdots \\\\ y^m\n",
    "\\end{bmatrix}, \\bf{w} = \\begin{bmatrix} \n",
    "w_0 \\\\w_1\\\\ \\vdots \\\\ w_n\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Note that we have an additional $w_0$ as the first element of $\\bf{w}$, but this is just for notation. In practice, $w_0$ serves the same purpose as $b$.\n",
    "\n",
    "In our example we have $n = 3$ features, $m = 200$ samples, which gives us the regression coefficients $w_0, w_1, w_2, w_3$ to estimate.\n",
    "\n",
    "The regression line is thus \n",
    "\n",
    "$$f_{\\bold{w}}(\\bold{{x}}) = w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3$$ \n",
    "\n",
    "With this equation we can predict the sale for a new sample $i$ by \n",
    "$$\\hat{y}^{(i)} = w_0 + w_1 \\cdot x_1^{(i)} + w_2 \\cdot x_2^{(i)} + w_3 \\cdot x_3^{(i)}$$ \n",
    "\n",
    "or using dot product \n",
    "\t$$\\hat{y}^i = \\bf{w}\\cdot\\bf{x}^{(i)}$$\n",
    "\n",
    "where $\\bf{x}^{(i)}$ = $[1, x_1^{(i)}, x_2^{(i)},x_3^{(i)} ]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's prepare our data like this\n",
    "\n",
    "X, y = df.drop(\"Sales\", axis=\"columns\"), df[\"Sales\"]\n",
    "X.insert(0, \"Intercept\", 1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we implement the closed form solution to obtain the weights\n",
    "\n",
    "weights = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)),X.T), y)\n",
    "\n",
    "for i, weight in enumerate(weights):\n",
    "    print(f'w_{i}: {weight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "Let's now use our model to predict some values $\\hat{y}$, and compare them with the true values $y$ found in the training data\n",
    "\n",
    "We will obtain $\\hat{y}^i$ using the dot product\n",
    " $$\\hat{y}^i = \\bf{w}\\cdot\\bf{x}^{(i)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10                 # change this to whichever training sample index you like \n",
    "\n",
    "y_hat = np.dot(weights, X.iloc[i])\n",
    "\n",
    "print(f'y_hat = {y_hat}')\n",
    "print(f'y     = {y[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Challenges\n",
    "\n",
    "**Task 1**\n",
    "\n",
    "Calculate MAE for the model we just fit. Is it better or worse at predicting sales numbers compared with the linear and polynomial regression models we fit using a single feature of the data?\n",
    "\n",
    "**Task 2**\n",
    "\n",
    "Nothing stop you from creating your own new features, and in turn using them as predictor variables in a multiple linear regression model. For example, we could combine the features TV and Newspaper by multiplying them and call this new feature $x_4$, as such:\n",
    "\n",
    "$$x_4 = TV \\cdot Newspaper$$\n",
    "\n",
    "We can then use this as another feature for our model. In fact, we can pick and chose exactly which features we want to use in our model, and which to exclude. \n",
    "\n",
    "For example, we could do something like this\n",
    "\n",
    "$$f_{\\bold{w}}(\\bold{{x}}) = w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_4$$\n",
    "\n",
    "The point is that you can create your own features as you like, and then pick and chose exactly which features to include in your model. Usually, this process is not random but informed by domain expertise about the data and the exact process we're trying to model.\n",
    "\n",
    "Your task now is to experiment with this. Create your own feature(s) and then use it/them as features for your multiple regression model. If you like, you can do exactly as we've done above. After you've fit the model, calculate the MAE. Is it better or worse than our original multiple regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
