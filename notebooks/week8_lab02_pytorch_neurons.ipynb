{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc50656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d7279",
   "metadata": {},
   "source": [
    "# Load and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720a1c3",
   "metadata": {},
   "source": [
    "**1) ladda**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47db2b",
   "metadata": {},
   "source": [
    "Vi kommer att använda följande dataset:\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance\n",
    "\n",
    "Vårt mål kommer vara att förutspå varje elevs slutbetyg, beroende på olika faktorer.\n",
    "I hemsidan kan du läsa på mer detaljerat om vad varje kolumn beskriver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = pd.read_csv('../data/students.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984bdd0",
   "metadata": {},
   "source": [
    "**2) Initial data check**\n",
    "\n",
    "Vi vill predikta 'G3' (slutbetyg) givet övriga attribut.\n",
    "\n",
    "Slutbetyget anges med ett värde på 0-20, där 20 är bästa betyg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e49328",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347dbff",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828f74c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(students_df.G3.value_counts())\n",
    "\n",
    "students_df.G3.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22252592",
   "metadata": {},
   "source": [
    "Som syns ovan ser vi att ingen fått maxbetyg (20) men att två elever uppnåde 19 iaf. De allra flesta verkar fått slutbetyg mellan 9 till 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd369334",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5fa6c",
   "metadata": {},
   "source": [
    "**3) välj bort vissa kolumner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vi väljer bort ett par kolumner för enkelhetens skull, och tar endast med ett par utvalda\n",
    "\n",
    "target_column = ['G3']\n",
    "feature_columns = ['school', 'sex', 'age', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'reason',\n",
    "                   'studytime', 'failures', 'higher', 'internet', 'Dalc', 'Walc', 'health', 'G1', 'G2']\n",
    "\n",
    "students_df = students_df[feature_columns + target_column]\n",
    "\n",
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df5e1f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a130c",
   "metadata": {},
   "source": [
    "**4) transformera data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7ceb2",
   "metadata": {},
   "source": [
    "Alla inputs och outputs för neurala nätverk måste först siffror (integer eller floats). Vi ser att flera av våra kolumner (bl.a. *school* och *sex*) inte är det, och behöver således åtgärda det. Ett av kolumnerna är dessutom kategorisk, men vi återkommer till den strax.\n",
    "\n",
    "Först och främst ser vi att ett antal kolumner (*school*, *sex*, *famsize*, *pstatus*, *higher* och *internet*) är binära - dvs att de bara antar två värden. Dessa kan vi helt enkelt omvandla dessa två värden till 1 och 0, respektive. \n",
    "\n",
    "**Kontrollera själv att kolumnerna ovan verkligen är binära**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['school', 'sex', 'famsize', 'Pstatus', 'higher', 'internet']\n",
    "\n",
    "for column in binary_columns:\n",
    "    \n",
    "    first_value = students_df[column].unique()[0] # extrahera ett av de binära värdena\n",
    "    transformed_column = [1 if value == first_value else 0 for value in students_df[column]]\n",
    "    \n",
    "    students_df[column] = transformed_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kontrollera nu att alla värden omvandlats till 1 och 0 i de binära kolumnerna\n",
    "\n",
    "for column in binary_columns:\n",
    "    print(students_df[column].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1da041",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b0d15",
   "metadata": {},
   "source": [
    "Nu återstår att åtgärda den kategoriska kolumnen *reason*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10599de1",
   "metadata": {},
   "source": [
    "Vi behöver göra om den här kolumnen till siffror, och en strategi för att hantera kategoriska kolumner är att omvandla dem \n",
    "till kolumner, en varje varje värde - och på enklaste sätt ange 1 eller 0 för respektive kolumn på de rader som värdet antas.\n",
    "\n",
    "Detta kallas också 'one-hot-encoding'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# För varje möjlig kategoriskt värde, loopa och konstruera en ny kolumn enligt ovan\n",
    "\n",
    "categorical_columns = ['reason']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    for value in set(students_df[column].values):\n",
    "    \n",
    "        onehotencode = [1 if x == value else 0 for x in students_df[column]]\n",
    "        students_df[value] = onehotencode\n",
    "    \n",
    "\n",
    "#slutligen, droppa orginalkolumnen som vi inte längre behöver    \n",
    "\n",
    "for column in categorical_columns:\n",
    "    students_df = students_df.drop(columns=[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea04dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79f2eb",
   "metadata": {},
   "source": [
    "Nu ser det redan bättre ut!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed95b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb150b30",
   "metadata": {},
   "source": [
    "Låt oss bara re-arrange så att slutbetyg-kolumnen (G3) är sista kolumnen i dataframet. Det blir lite lättare då."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19119ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = students_df.pop('G3') #droppa columnen från students_df, och fånga upp den i variablen g3\n",
    "students_df['G3'] = g3     #lägg tillbaks kolumnen. På detta sätt hamnar den på sista plats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf89f28",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26782979",
   "metadata": {},
   "source": [
    "Nu går vi vidare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54455aba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640886a",
   "metadata": {},
   "source": [
    "**5) skala data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbced00",
   "metadata": {},
   "source": [
    "Vi ser nu att samtliga kolumner är av rätt datatyp.\n",
    "\n",
    "Det som återstår är att *normalisera* **input** kolumnerna. Detta är **superviktigt** att göra när man tränar neurala nätverk, för att ingen enstaka kolumn ska dominera de övriga i storlek. I vårt fall är det inte så illa, eftersom att värdena bland alla input kolumner är mellan 0 och som högst 20. \n",
    "\n",
    "Men, vi normaliserar iaf - det är best practice.\n",
    "\n",
    "Detta kan göras på olika sätt, men vanligtvis innebär detta att man skalar om värdena i respektive kolumn till att vara mellan [0,1] eller [-1,1]. Det spelar egentligen inte särskilt stor roll vilken av dessa skalor man väljer, men jag brukar välja [0,1] för kolumner som bara ha positiva värden, och [-1,1] för kolumner som har både positiva och negativa värden.\n",
    "\n",
    "Eftersom att alla våra inputkolumner endast antar positiva värden, \n",
    "\n",
    "kan vi således försöka skala de till [0,1]. Ett enkelt knep för att åstadkomma detta är helt enkelt att dela varje kolumn på sitt högsta värde.\n",
    "\n",
    "OBS: Vi normaliserar **inte** vår target kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = students_df.columns[:-1]\n",
    "\n",
    "for feature in feature_columns:\n",
    "    \n",
    "    students_df[feature] = students_df[feature]/max(students_df[feature].values) #dela varje inputkolumn på sitt högsta värde\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38926e4a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74cf6b",
   "metadata": {},
   "source": [
    "Sista steget är att omvandla datan till ett format som är optimalt för PyTorch. Ett format som kallas för *tensor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.tensor(students_df.values).float()            #nu är allt klart, så vi anger detta som vår training_set\n",
    "\n",
    "#säkerställ att datasetet är av samma storlek\n",
    "\n",
    "print(students_df.shape)\n",
    "\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set           # visualisera hela tensor-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62362a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[:,-1]     # precis som vanligt kan vi ex få sista kolumnen (vilket motsvarar vår target \n",
    "                       # slutbetyg i detta fall) genom denna query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41ada8",
   "metadata": {},
   "source": [
    "**Sådär, all done. Nu kan vi gå vidare!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7a167",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ddceb",
   "metadata": {},
   "source": [
    "# Skapa Neurons med PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75207972",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac154a1",
   "metadata": {},
   "source": [
    "Att skapa modeller med PyTorch görs allra oftast via klasser. Lyckligtvis är detta supersimpelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08070a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class neuron(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(neuron, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95018f71",
   "metadata": {},
   "source": [
    "Vår input size till modellen är ju alla våra features, och de har vi 20 st av. **Eller hur?!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "\n",
    "model = neuron(input_size) # initiera en instans av vår neuron-klass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0968a",
   "metadata": {},
   "source": [
    "Vi kan se en summary av vår modell genom att kalla på den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfeaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44a590",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82abcac",
   "metadata": {},
   "source": [
    "Om vi vill kan vi direkt räkna ut antal parametrar genom följande kodsnutt\n",
    "\n",
    "**Fråga: varför är antalet parametrar som det är?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962fba9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422a8e0",
   "metadata": {},
   "source": [
    "Vi kan läsa av dessa parametrar direkt via model.parameters(), där de är lagrade\n",
    "\n",
    "Lägg märke till att sifforna är helt random inom intervallet [-1,1]. \n",
    "\n",
    "**För att kontrollera detta, testa att initiera om modellen ovan, och dra följande kodsnutt igen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854694f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights, bias = model.parameters()\n",
    "\n",
    "print('vikter')\n",
    "print(weights, end='\\n\\n')\n",
    "\n",
    "print('bias')\n",
    "print(bias, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892c4e0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b8bfd",
   "metadata": {},
   "source": [
    "För att ge input till vår modell, och få en output gör man helt enkelt såhär:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_student = training_set[0,:-1]      # ta den första studentens input features (första raden)\n",
    "sample_grade = training_set[0,-1]         # extrahera även den studentens slutbetyg\n",
    "\n",
    "model_prediction = model(sample_student)  # predicta ett slutbetyg med vår färskt initierade modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259bcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True grade            :', sample_grade.item())\n",
    "print('Vår models predict    :', model_prediction.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf8ac0",
   "metadata": {},
   "source": [
    "Ha, katastrofalt fel! \n",
    "\n",
    "Sifforna är inte ens i närheten av nära, eller hur? :) \n",
    "\n",
    "Det är OK, för vi har inte börjat träna.\n",
    "\n",
    "Men nu är dags!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba870b6c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb4beb",
   "metadata": {},
   "source": [
    "## Träna med PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea04962",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81435d45",
   "metadata": {},
   "source": [
    "Vi väljer först en loss function. Eftersom att vi kör regression kan vi exempelvis välja Mean Absolute Error (MAE) loss - även mer tekniskt kallat för L1 Loss. \n",
    "\n",
    "Kom ihåg att det här kommer användas för att kvantifier avståndet mellan våra prediktions och det sanna värdet. Vi kommer alltså vilja minimera denna loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf9baf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5de68",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af972fa",
   "metadata": {},
   "source": [
    "Vi väljer också en så kallad optimizer. Det är den här som kommer utföra själva gradient descent steget vi pratat om.\n",
    "\n",
    "Notera här att vi också lägger in en parameter kallad *lr*. Detta är learning rate vi också pratat om, och bestämmer hur stort steg varje gradient descent tar när den uppdaterar våra parametrar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae82c3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2629bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr = 0.001) # observera att vi här visar vår optimizer vilka modellens parametrar är, \n",
    "                                                # så att den vet vad ska uppdatera "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786171d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb3c9b",
   "metadata": {},
   "source": [
    "Nu under träningens gång så kommer inte vi skicka in hela datasetet på en gång, utan vi skickar in ett par training samples åt gången. Antalet samples vi skickar in per iteration kallas för *batch size*. Varför varje sådan batch kommer vi att utföra gradient descent och uppdatera (träna) våra parametrar. Mer om detta längre ner.\n",
    "\n",
    "Vanliga batchsizes är typ mellan 16-128. Vi kan gott köra med 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a26c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                  # det är denna funktion som kommer ansvara för att leverera\n",
    "                              batch_size = 16,               # samples till modellen under träningens gång\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f1601",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d986b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff84bc0",
   "metadata": {},
   "source": [
    "**Lite mer om dataloader och bathsize:**\n",
    "\n",
    "När vi väljer batch_size = 16 så kommer den, för varje gång den blir kallad, att välja randomly 16 stycken training samples som den levererar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0c1f8",
   "metadata": {},
   "source": [
    "Vi kan också se hur en sådan här batch ser ut, samt den första training samplen ur den batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    \n",
    "    print(batch.size(), end='\\n\\n') # visa storleken för hela den här batchen\n",
    "    \n",
    "    print(batch[0,-1])              # printa första training samples slutbetyg, i den här batchen\n",
    "    print(batch[0,:-1])             # printa alla feature kolumns för första training sample i den här batchen\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a55ed",
   "metadata": {},
   "source": [
    "Vi ser att det är totalt 16 rader (training samples) i batchen, och 21 kolumner. Den sista kolumnen i varje rad motsvarar slutbetyg, precis som tidigare - och övriga är våra input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96723d5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b23979",
   "metadata": {},
   "source": [
    "Hur många batches har dataloader till oss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea6199",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6923e1",
   "metadata": {},
   "source": [
    "Vi kan även, för tydlighetens skull, se antalet training samples i varenda sådan batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a88e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_nummer = 0\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    \n",
    "    batch_nummer += 1\n",
    "\n",
    "    print(f'Batch: {batch_nummer}.  ',f'Antal samples: {len(batch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbccb2",
   "metadata": {},
   "source": [
    "Om vi summerar antalet samples som levererades totalt av våra 41 batches ovan blir det exakt 649 - vilket är storleken på vårt dataset. DataLoader kommer alltså leverera (efter en komplett for-loop) lika manga training samples som storleken på vårt dataset!\n",
    "\n",
    "Som vi ser försöker den ge 16 samples för varje batch, förutom den sista – eftersom att vi skulle överskrida storleken på vårt dataset. Räkna ihop antalet ovan, och jämför med len(training_set).\n",
    "\n",
    "**Viktigt begrepp**:\n",
    "\n",
    "En komplett for-loop genom DataLoader kallas för en **epoch**. \n",
    "\n",
    "Dvs, när vår modell fått träna på lika manga samples som storleken på vart dataset, så sager vi att modellen fått träna i en epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9c6e8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af033d66",
   "metadata": {},
   "source": [
    "**Nu kör vi hela träningsloopen**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906770b6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ändra inget av det här, förens du blir instruerad till det\n",
    "\n",
    "input_size = 20                       \n",
    "batch_size = 16\n",
    "\n",
    "epochs = 100               # antal loopar genom dataloader vi låter vår modell träna på vårt dataset.\n",
    "learning_rate = 0.001      # hur stora steg gradient descent tar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55113b1",
   "metadata": {},
   "source": [
    "Som ni ser i träningskoden nedan är värdet på epochs antal gånger som vi kommer gå igenom datan i vår train_dataloader. \n",
    "\n",
    "Eftersom att vår train_dataloader innehar 41 batches, så kommer vi totalt att låta algoritmen gå igenom (41 x epochs) batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8c055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    initera modell, loss_function, optimizer & dataloader\n",
    "\n",
    "\n",
    "model = neuron(input_size)           \n",
    "loss_function = torch.nn.L1Loss() \n",
    "optimizer = SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                 \n",
    "                              batch_size = batch_size,       \n",
    "                              shuffle=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    träna\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "    \n",
    "        y_true = batch[:,-1]\n",
    "        input_features = batch[:,:-1]\n",
    "\n",
    "        y_pred = model(input_features)\n",
    "        loss = loss_function(y_true, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        batch_losses.append(batch_loss)\n",
    "        \n",
    "        print(np.round(batch_loss,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9d7a2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16143e21",
   "metadata": {},
   "source": [
    "Vi kan nu plotta loss-historiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195de923",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(batch_losses);\n",
    "plt.xlabel('batch');\n",
    "plt.ylabel('training loss (MAE)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657e46e",
   "metadata": {},
   "source": [
    "Losset som beräknades under den allra sista iteration av träning är"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54178bf",
   "metadata": {},
   "source": [
    "Detta betyder att *medelfelet* av våra prediktions, på hela vårt träningssätt är det värdet du ser ovan! Men betygen för varje person är ju också satt mellan 0-20, så ett medelfel på värdet du ser ovan är inte helt katastrofalt dåligt.\n",
    "\n",
    "Det är ju dock ändå knappast optimalt - och anledningen är för att en Neuron är en ganska dålig modell :)\n",
    "\n",
    "Här ville vi ju dock bara lära oss grunderna i PyTorch. Vi kommer lära oss betydligt bättre kraftfullare modeller snart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221c4e6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b486c3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c44d2",
   "metadata": {},
   "source": [
    "## UPPGIFTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb36044",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17113e9",
   "metadata": {},
   "source": [
    "**0)**\n",
    "\n",
    "Kolla på plotten över lossen ovan. Hur tolkar du den? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e66a9",
   "metadata": {},
   "source": [
    "**1)** \n",
    "\n",
    "Låt oss direkt testa hur den tränade modellen presterar på vårt dataset. Välj själv en training sample, ange ett värde mellan 0-648.\n",
    "\n",
    "Kan du hitta några training samples som modellen predictar särskilt bra/dåligt på? Jämför felen du får i dina svar med medelfelet vi fick ovan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebd3fa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();                                        # sätt modellen i evaluerings/predicion läge\n",
    "\n",
    "training_sample = 100                                 # TESTA OLIKA VÄRDEN PÅ DENNA\n",
    "\n",
    "y_true = training_set[training_sample, -1]           # extrahera sanna slutbetyget för givet training sample\n",
    "input_features = training_set[training_sample, :-1]  # extrahera alla input features för samma training sample\n",
    "\n",
    "y_prediction = model(input_features)                 # predicta slutbetyg, givet input features\n",
    "\n",
    "\n",
    "print('True grade       :', y_true.item())\n",
    "print('Predicted grade  :', y_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0d259",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11104bb6",
   "metadata": {},
   "source": [
    "**2)**\n",
    "\n",
    "Åskådliggör modellens parametrar på nytt. \n",
    "\n",
    "Säkerställ att de har ändrats sedan vi initierade modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d36b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9f3a4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd26a6",
   "metadata": {},
   "source": [
    "**3)**\n",
    "\n",
    "Gå nu tillbaks till träningsloopen och testa att köra igenom den för ett par olika värden på epochs, och plotta på nytt. \n",
    "\n",
    "Testa värden på epochs med början på 1 och sluta på 50. Exempelvis 1, 5, 10, 15, ..., 45, 50.\n",
    "\n",
    "Vad verkar hända?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee789c5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d098f6c",
   "metadata": {},
   "source": [
    "**4)**\n",
    "\n",
    "Återigen, gå tillbaks till träningsloopen. Sätt epochs = 100. Testa nu istället olika värden på learning rate\n",
    "\n",
    "Testa följande värden på learning rate, i tur ordning\n",
    "\n",
    "- 0.00001 \n",
    "- 0.01\n",
    "- 1\n",
    "\n",
    "och plotta på nytt vår loss. Vad verkar hända? \n",
    "\n",
    "*Hint: jämför lossen* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
