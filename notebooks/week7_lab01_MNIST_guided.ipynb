{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d9e76",
   "metadata": {},
   "source": [
    "**Objective and goal for this lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca903507",
   "metadata": {},
   "source": [
    "For this lab, we're going to see how we can transform images to a format we're used to working with, and can thus use for training classification (or regression) models.\n",
    "\n",
    "We will be using the MNIST-dataset, which is a famous dataset of handwritten black & white digits between 0-9. Our goal will be to train a classifier to correctly classify each image as the digit it portrays.\n",
    "\n",
    "You can read more about MNIST [here](https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50fda6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dc3c8",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        return np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num = struct.unpack(\">II\", f.read(8))\n",
    "        return np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "# Load training data\n",
    "train_images = load_mnist_images(\"../data/mnist/train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"../data/mnist/train-labels.idx1-ubyte\")\n",
    "\n",
    "# Load test data\n",
    "test_images = load_mnist_images(\"../data/mnist/t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"../data/mnist/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce9ada",
   "metadata": {},
   "source": [
    "Let's investigate what we just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_images shape :', train_images.shape)\n",
    "print('test_images shape  :', test_images.shape, end='\\n\\n')\n",
    "\n",
    "print('train_labels shape :', train_labels.shape)\n",
    "print('test_labels shape  :', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db896dd",
   "metadata": {},
   "source": [
    "So both train and test images are 3D-arrays. Let's pick the first item in train_images and investigate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_images[0] :', train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5902193",
   "metadata": {},
   "source": [
    "So, the first (out of 60.000) items in train_images is a 28x28 array. Actually, it's an image of size 28x28 pixels.\n",
    "\n",
    "We can visualise this easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa569ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0], cmap='gray');\n",
    "plt.title(f'Label: {train_labels[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56994c46",
   "metadata": {},
   "source": [
    "As you might've noticed, the train_labels contain the true labels (i.e., the targets) for each handwritten image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9a0ed",
   "metadata": {},
   "source": [
    "Let's plot some more images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "number_of_images = 10\n",
    "\n",
    "indices = random.sample(range(60000), number_of_images)\n",
    "\n",
    "fig, axes = plt.subplots(1, number_of_images, figsize=(15, 3))\n",
    "\n",
    "for idx, ax in zip(indices, axes):\n",
    "    ax.imshow(train_images[idx], cmap='gray')\n",
    "    ax.set_title(f'Label: {train_labels[idx]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51070090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc678f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cd1bb",
   "metadata": {},
   "source": [
    "Ok, so how do we transform this data into a format that we can train the models we've learnt about thus far? \n",
    "\n",
    "Well,  what we'll do is that we're going to use *every pixel as it's own feature*. Since each image is 28x28 pixels, we're going to have 28x28 = 784 features for each image.\n",
    "\n",
    "We can use flatten() to transform a 2D (28,28) shaped array to a single 1D (784) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494dcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy transformation\n",
    "\n",
    "train_images[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do it for all the images in the train_images\n",
    "\n",
    "train_images_flattened = [list(image.flatten()) for image in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd534722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_flattened_array = np.array([image.flatten() for image in train_images])\n",
    "\n",
    "# transform that list to a dataframe so that we can see what's going on\n",
    "X_train_val = pd.DataFrame(train_images_flattened_array)\n",
    "\n",
    "X_train_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7240f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might aswell make the labels into a dataframe too\n",
    "\n",
    "y_train_val = pd.DataFrame(train_labels)\n",
    "\n",
    "y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8877e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652eeedd",
   "metadata": {},
   "source": [
    "Cool, no we're on familiar ground! We have our X_train_val (features) and y_train_val (targets) in a suitable format.\n",
    "\n",
    "Now we can try training some multiclass classification models on this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84120a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fe82d",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cdda2",
   "metadata": {},
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c445c8",
   "metadata": {},
   "source": [
    "Transform test_images and test_labels similarly as above, and save them as X_test and y_test.\n",
    "\n",
    "This is the test set you will use at the end, to assess final performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do it for all the images in the test_images\n",
    "\n",
    "test_images_flattened = [list(image.flatten()) for image in test_images]\n",
    "\n",
    "test_images_flattened_array = np.array([image.flatten() for image in test_images])\n",
    "\n",
    "# transform that list to a dataframe so that we can see what's going on\n",
    "X_test = pd.DataFrame(test_images_flattened_array)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(test_labels)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e479ab",
   "metadata": {},
   "source": [
    "**Task 1.5 (bonus**)\n",
    "\n",
    "Let's normalize our features! Because why not. It won't hurt the algorithms that don't require it - and we might aswell show how easily images can be scaled properly.\n",
    "\n",
    "In the case for gray-scale images, we simply divide all features (pixels) by 255. Why? Because that's the maximum possible value. This will bring all grayscale values to the range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56db7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = X_train_val/255\n",
    "\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2de3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63c908",
   "metadata": {},
   "source": [
    "Awesome. Done. Feel free to check that all grayscale values are properly scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38df6c5",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Using all 784 features (no additional feature engineering or manipulation needed), start GridSearching for the best performing hyperparameters for \n",
    "\n",
    "KNN, DecisionTree, RandomForest, AdaBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0441a",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "When you have the best performing hyperparameters, do an ordinary train/validation split on X_train_val and y_train_val.\n",
    "\n",
    "Train the models with their respective best performing hyperparameters on X_train and then evaluate performance on X_val.\n",
    "\n",
    "In particular, make good use of confusion matrices here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03488f04",
   "metadata": {},
   "source": [
    "**Task 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99670e",
   "metadata": {},
   "source": [
    "For the models you've trained in Task 3, try plotting the validation samples they classified **incorrectly**. As the title for each image, write the true label and the predicted label.\n",
    "\n",
    "Do the mistakes kinda make sense? Can you forgive your models? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ffbdb",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "\n",
    "For each model with the identified best performing hyperparameters, do a full training on X_train_val - then assess performance on X_test.\n",
    "\n",
    "Which model did you find to perform worst/best? Is the difference large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ec9e9",
   "metadata": {},
   "source": [
    "*We're going to pretend that the default hyperparameters are best here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8085c",
   "metadata": {},
   "source": [
    "Train and predict with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d550acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e52e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25834a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred_probabilities = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dfaad",
   "metadata": {},
   "source": [
    "Train and predict with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cf3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16075c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_probabilities = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cad73b",
   "metadata": {},
   "source": [
    "Evaluate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=knn_pred.reshape(-1,1))\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"Accuracy:\", accuracy, end='\\n\\n')\n",
    "\n",
    "report = classification_report(y_test, knn_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75689660",
   "metadata": {},
   "source": [
    "Evaluate RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=rf_pred.reshape(-1,1))\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Accuracy:\", accuracy, end='\\n\\n')\n",
    "\n",
    "report = classification_report(y_test, rf_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ad854",
   "metadata": {},
   "source": [
    "Let's plot missclassifcations made by the RF, for some error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(rf_pred != y_test.values.ravel())[0]\n",
    "\n",
    "misclassified_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(misclassified_indices)\n",
    "\n",
    "num_images_to_display = 10\n",
    "\n",
    "num_displayed = 0\n",
    "\n",
    "for i in misclassified_indices:\n",
    "    if num_displayed >= num_images_to_display:\n",
    "        break\n",
    "\n",
    "    predicted_class = rf_pred[i]\n",
    "    correct_class = y_test.values.ravel()[i]\n",
    "\n",
    "    predicted_class_probability = rf_pred_probabilities[i][predicted_class]\n",
    "    correct_class_probability = rf_pred_probabilities[i][correct_class]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[i], cmap='gray')\n",
    "    plt.title(f\"Predicted as {predicted_class}, Actual: {correct_class}\\n\\n\"\n",
    "              f\"Probabilities per class\\n\" \n",
    "              f\"Class {predicted_class} : {predicted_class_probability}, Class {correct_class} : {correct_class_probability}\\n\\n\"\n",
    "              'All probabilities\\n'\n",
    "              f\"{rf_pred_probabilities[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    num_displayed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf94bc4",
   "metadata": {},
   "source": [
    "**Task 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cd099",
   "metadata": {},
   "source": [
    "If you feel frisky, you can try a tad more difficult problem. Try loading and training on the [Fashion MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist) dataset instead. \n",
    "\n",
    "It's a relatively more difficult dataset to classify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
