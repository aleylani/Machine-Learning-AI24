{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the used_cars dataset\n",
    "used_cars_df = pd.read_csv('../data/used_cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuation\n",
    "\n",
    "We're now going to build upon the first lab of the week by now introucing multiple linear regression in sklearn.\n",
    "\n",
    "We'll begin by pretty much the same EDA and cleaning as the other lab, with some extra steps (that you should've done in previous lab's tasks) - so you can simply follow along here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA) and data cleaning\n",
    "\n",
    "The target for our regression problem here is the column *price*. \n",
    "\n",
    "Each row represent the characteristics of a car, and the corresponding sales price of said car. We are free to choose which of the available features to fit a model to, and try to predict the target with.\n",
    "\n",
    "It's generally essential that we use our wits and domain expertise to pick and engineer good features for our model. Bad features will produce a bad model, with poor predictie power. In other word, a useless model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove a redundant column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first column which looks like a copy of the index column\n",
    "\n",
    "columns_to_keep = used_cars_df.columns[1:]\n",
    "print(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keep only numerical columns, for now**\n",
    "\n",
    "Many machine learning models require that the input are all numerical (since you can't do mathematic operations with anything else), and it is therefore essential that (when using models with that requirement) make sure that the data satisfies that condition.\n",
    "\n",
    "Note that there are ways to transform any given column into numericals that we can work with, but let's hold on with that for now and only keep the features that already are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "used_cars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal with missing data**\n",
    "\n",
    "Let's try to find and mitigate missing data. Note that whether to remove data points is a very sensitive decision, and should be carefully considered. \n",
    "\n",
    "Augmenting and fixing the data is a better alternative, if the time to do so is available. \n",
    "\n",
    "All changes we do to the training data *will* affect our model's performance, either insignificantly or significantly - depending on the changes we've made, and to what extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null-data\n",
    "\n",
    "used_cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df.dropna().reset_index(drop=True)\n",
    "\n",
    "used_cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with unreasonable data**\n",
    "\n",
    "Usually, we have to spend considerable time to just clean the data and get rid of crap that has nested it's way into it.\n",
    "\n",
    "Crap in data is very common in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by trying to understand the price column a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(used_cars_df['price(in lakhs)'], bins=50);\n",
    "plt.xlabel('price(in lakhs)');\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's strange, it looks like there are a few cars that are extremely expensive. This is not incorrect per se, but let's look deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df[used_cars_df['price(in lakhs)']>100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have 3 records of cars that looks to suspicous.\n",
    "\n",
    "Since Ali has been in India, he knows that 1 lakh is a common indian measure that means one hundred thousand (indian rupees, in this case).\n",
    "\n",
    "70000 lakhs is therefore 70000 * 100.000 = 7000000000 (indian rupees).\n",
    "\n",
    "Converting this to Swedish currency we get 877447200 SEK. Not reasonably at all. \n",
    "\n",
    "Let's just remove these records for simplicity, and plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df[used_cars_df['price(in lakhs)']<12.5].reset_index(drop=True)\n",
    "\n",
    "plt.hist(used_cars_df['price(in lakhs)'], bins=50);\n",
    "\n",
    "plt.xlabel('price(in lakhs)');\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, now it looks much more realistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, great. Let's also take a look at kms_driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(used_cars_df['kms_driven'], bins=50, color='green');\n",
    "\n",
    "plt.xlabel('kms_driven');\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this also looks a little suspicious. Perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df[used_cars_df['kms_driven']>150000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so there are only 6 cars that have droven over 150.000 kms. Let's remove them, since they deviate in too much in values from our other values, and thus much deteroriate the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df[used_cars_df['kms_driven']<150000].reset_index(drop=True)\n",
    "\n",
    "plt.hist(used_cars_df['kms_driven'], bins=50, color='green');\n",
    "\n",
    "plt.xlabel('kms_driven');\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we now don't have any cars with high mileage in our training data at all. This is perfectly fine, but you should **not** try to use this resulting model to predict the price of cars with high mileage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at kmpl now. This means kilometers per liter. What are reasonable values for this, do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df[used_cars_df['mileage(kmpl)']<30].reset_index(drop=True)\n",
    "\n",
    "plt.hist(used_cars_df['mileage(kmpl)'], bins = 20, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(used_cars_df['mileage(kmpl)'], used_cars_df['price(in lakhs)']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look carefully, engine(cc) and max_power(bhp) is the same column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df = used_cars_df.drop(columns=['max_power(bhp)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, looks like we have a good range with a good amount of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cars_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's try to use all our features to predict our target, the sales price.\n",
    "\n",
    "We'll use a linear model for this. In other words, We'll now assume that we can model\n",
    "\n",
    "$$ price = w_5 \\cdot (seats) + w_4 \\cdot (kms\\ driven) + w_3 \\cdot (mileage(kmpl)) + w_2 \\cdot (engine(cc)) + w_1 \\cdot (torque(Nm)) + w_0$$\n",
    "\n",
    "**note** That we'll have a difficult time doing any plots here, since our eyes are limited to 3D while have 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = used_cars_df.drop(columns=['price(in lakhs)', 'seats']).values, used_cars_df['price(in lakhs)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all our features are here now\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# our target column has the same shape as before\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that our features X has the required shape format, but the target y doesn't. So let's fix that now\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # set a random state, so we can reproduce our results\n",
    "\n",
    "print('Train set:')\n",
    "print('X:', len(X_train))\n",
    "print('y:', len(y_train), end='\\n\\n')\n",
    "\n",
    "print('Test set:')\n",
    "print('X:', len(X_test))\n",
    "print('y:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a linear regression model and the MSE-metric from sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "multiple_linear_regression_model = LinearRegression()     # note that this model has inate support to handle several features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "multiple_linear_regression_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the weights of the trained model\n",
    "\n",
    "print(multiple_linear_regression_model.intercept_)\n",
    "print(multiple_linear_regression_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for both the train and test set\n",
    "\n",
    "y_train_hat = multiple_linear_regression_model.predict(X_train)\n",
    "y_test_hat = multiple_linear_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE for both sets\n",
    "\n",
    "print('Train:')\n",
    "print(f'MSE: {mean_squared_error(y_train, y_train_hat)}')\n",
    "\n",
    "print('Test:')\n",
    "print(f'MSE: {mean_squared_error(y_test, y_test_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_test_hat);\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_test_hat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this result compare to the regression models you built using only one feature in the previous lab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challanges\n",
    "\n",
    "**Task 1**\n",
    "\n",
    "Try re-training the multiple linear regression model above, each time removing a single feature. I.e., you should train 5 models with the following features respectively:\n",
    "\n",
    "1. $x_1, x_2, x_3, x_4$\n",
    "\n",
    "2. $x_1, x_2, x_3, x_5$\n",
    "\n",
    "3. $x_1, x_2, x_4, x_5$\n",
    "\n",
    "4. $x_1, x_3, x_4, x_5$\n",
    "\n",
    "5. $x_2, x_3, x_4, x_5$\n",
    "\n",
    "Does any of the above combinations of features yield a better performing model? Or perhaps our efforts to model used care prices using only these features from this specific dataset is simply futile..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
