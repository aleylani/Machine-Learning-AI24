{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8771c6a",
   "metadata": {},
   "source": [
    "**Motivation & objective**\n",
    "\n",
    "Imbalanced datasets are ubiquitous in real-world machine learning tasks, where one class significantly outnumbers the other(s). While this scenario is common, it poses significant challenges for traditional machine learning algorithms, which tend to be biased towards the majority class and perform poorly on minority classes. In this lab, we will explore three techniques to address the imbalance issue: subsampling, oversampling, and Synthetic Minority Over-sampling Technique (SMOTE). By implementing these techniques, we aim to improve the model's performance on imbalanced datasets and make our predictions more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003b63b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd0427",
   "metadata": {},
   "source": [
    "**Importing the Dataset**:\n",
    "\n",
    "Let's start by importing the Credit Card Fraud Detection dataset, a real-world example of an imbalanced dataset where fraudulent transactions are the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf70b2",
   "metadata": {},
   "source": [
    "*Download the dataset here!!*\n",
    "\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first rows of this dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1db660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is extremely imbalanced\n",
    "\n",
    "df['Class'].value_counts()\n",
    "\n",
    "# but also expected, since frauds are a mere fraction of all transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ac408",
   "metadata": {},
   "source": [
    "**Train/Test Split and Baseline Model**\n",
    "\n",
    "Before applying any techniques to handle the imbalance, let's establish a baseline model. \n",
    "\n",
    "We'll perform a simple train/test split and train a RandomForest classifier on the training set, evaluating its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ef9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "\n",
    "X,y = df.drop(columns=['Class']), df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb28b8",
   "metadata": {},
   "source": [
    "As we can see below, both splits are also heavily imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccab354",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10577399",
   "metadata": {},
   "source": [
    "Training a RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e12f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db900d93",
   "metadata": {},
   "source": [
    "Evaluating it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d3372",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f80c2a",
   "metadata": {},
   "source": [
    "**Subsampling**\n",
    "\n",
    "Subsampling involves reducing the number of samples in the majority class to balance the dataset. \n",
    "\n",
    "*However, it's essential to perform subsampling only on the training set to avoid information loss in the test set.* \n",
    "\n",
    "This point actually stands for any other sampling method aswell. We want our test set to represent reality, and we therefore, as usual, can't alter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the imblearn-package\n",
    "\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb24234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Subsampling the majority class in the training set\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this is now balanced!\n",
    "\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e919a",
   "metadata": {},
   "source": [
    "Training a RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a new RandomForest classifier on the resampled data\n",
    "\n",
    "rf_classifier_resampled = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_resampled.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ed001",
   "metadata": {},
   "source": [
    "Evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_resampled = rf_classifier_resampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred_resampled)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_resampled = accuracy_score(y_test, y_pred_resampled)\n",
    "precision_resampled = precision_score(y_test, y_pred_resampled)\n",
    "recall_resampled = recall_score(y_test, y_pred_resampled)\n",
    "\n",
    "print(\"Subsampling Model Performance:\")\n",
    "print(\"Accuracy:\", accuracy_resampled)\n",
    "print(\"Precision:\", precision_resampled)\n",
    "print(\"Recall:\", recall_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cd211",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f8ff9",
   "metadata": {},
   "source": [
    "**Oversampling**\n",
    "\n",
    "Oversampling involves increasing the number of samples in the minority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Oversampling the minority class in the training set\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265214fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that this is now balanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b154498",
   "metadata": {},
   "source": [
    "Train a RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cff9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_oversampled = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_oversampled.fit(X_train_oversampled, y_train_oversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be02d58",
   "metadata": {},
   "source": [
    "Evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01063b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_oversampled = rf_classifier_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred_oversampled)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_oversampled = accuracy_score(y_test, y_pred_oversampled)\n",
    "precision_oversampled = precision_score(y_test, y_pred_oversampled)\n",
    "recall_oversampled = recall_score(y_test, y_pred_oversampled)\n",
    "\n",
    "print(\"\\nOversampling Model Performance:\")\n",
    "print(\"Accuracy:\", accuracy_oversampled)\n",
    "print(\"Precision:\", precision_oversampled)\n",
    "print(\"Recall:\", recall_oversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7fdc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a18da",
   "metadata": {},
   "source": [
    "**SMOTE (Synthetic Minority Over-sampling Technique)**\n",
    "\n",
    "SMOTE generates synthetic samples for the minority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Applying SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this is now balanced\n",
    "\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875b943",
   "metadata": {},
   "source": [
    "Train a RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f240aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_smote = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_smote.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7936ca",
   "metadata": {},
   "source": [
    "Evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = rf_classifier_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred_smote)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f998342",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "precision_smote = precision_score(y_test, y_pred_smote)\n",
    "recall_smote = recall_score(y_test, y_pred_smote)\n",
    "\n",
    "print(\"\\nSMOTE Model Performance:\")\n",
    "print(\"Accuracy:\", accuracy_smote)\n",
    "print(\"Precision:\", precision_smote)\n",
    "print(\"Recall:\", recall_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf728cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8452dce",
   "metadata": {},
   "source": [
    "## Challenges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d1965",
   "metadata": {},
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e6481",
   "metadata": {},
   "source": [
    "Understand everything we've done above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ee2fc",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Recall that we in the binary classification case, predict the class which has the biggest probability. \n",
    "\n",
    "Since there are only 2 classes, we predict the one which has 0.5 (by default).\n",
    "\n",
    "However, oftentimes it's worth altering this prediction threshold/cutoff to something else. This way, we can also affect our accuracy/precision/recall.\n",
    "\n",
    "Run the code below to see how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all prediction probabilities\n",
    "\n",
    "prediction_probabilities = rf.predict_proba(X_test)\n",
    "\n",
    "# extract only the probabilities for the positive class\n",
    "\n",
    "prediction_for_positive_class = prediction_probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of threshold values\n",
    "\n",
    "threshold_values = np.linspace(0.2,0.8,25)\n",
    "\n",
    "threshold_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bb518",
   "metadata": {},
   "source": [
    "The above threshold values are what we will loop over below. Specifically, each threshold represents the required probability for class 1 for us to predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbad370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each threshold value\n",
    "for threshold in threshold_values:\n",
    "\n",
    "    # Convert predicted probabilities to binary predictions based on the current threshold\n",
    "    y_pred = (prediction_for_positive_class >= threshold).astype(int)\n",
    "    \n",
    "    accuracy = round(accuracy_score(y_test, y_pred),4)\n",
    "    precision = round(precision_score(y_test, y_pred),4)\n",
    "    recall = round(recall_score(y_test, y_pred),4)\n",
    "    \n",
    "    # Print the metrics for the current threshold\n",
    "    print(f'Threshold : {round(threshold,2)}')\n",
    "    print(f'Accuracy  : {accuracy}')\n",
    "    print(f'Precision : {precision}')\n",
    "    print(f'Recall    : {recall}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8e288",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "Do the above analysis again, but instead use the classifiers you've trained on the differently pre-processed training sets above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
