{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "For this lab, we're going to use everything we've learned so far and try to predict bike demand using linear models!\n",
    "\n",
    "The data comes from this [page](https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Download the dataset. \n",
    "    \n",
    "In fact, by doing so you'll get two datasets. One is *daily* bike demand, and the other is *hourly* bike demand.\n",
    "The daily dataset has fewer records (731) and might be a bit simpler to work with if you're just getting started.\n",
    "If you want to have a bit more fun, go for the hourly dataset (17379 records).\n",
    "\n",
    "Pick the one you want! \n",
    "\n",
    "    2. Read carefully through the documentation for the dataset. \n",
    "\n",
    "The download will also include a *readme* with good information about the dataset and descriptions for all the columns in it. The target we're going to try to model is the column *cnt*. \n",
    "\n",
    "You are forbidden to use the columns *casual* and *registered*. Why do you think that is?\n",
    "\n",
    "    3. Conduct some initial EDA.\n",
    "\n",
    "Get to know the data by e.g. doing some initial plots and some statistics in order to try to understand what you're dealing with. \n",
    "\n",
    "While doing this, also think carefully about what features you'd think are relevant to what we're trying to predict. \n",
    "\n",
    "Which feature(s) do you have reasons to believe might be the individually most reliable one(s) to predict the demand?\n",
    "\n",
    "    4. Clean data\n",
    "\n",
    "If warranted, start cleaning data.\n",
    "\n",
    "    5. Model\n",
    "\n",
    "Pick the features you think or have reasons to believe are relevant. Then, train a linear model and evaluate it. Does it perform well?\n",
    "\n",
    "In this step, you are of course allowed to train many different models (all with different features). \n",
    "\n",
    "Can you find a particular combination of features that seem to work best?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the dataset\n",
    "bike_rental_df = pd.read_csv('../../data/bike_rental/hour.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rental_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rental_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unique values per column\n",
    "print(\"Number of unique values per column:\\n\")\n",
    "for col in bike_rental_df.columns:\n",
    "    if len(col)<6:\n",
    "        sep = \"\\t\\t\"\n",
    "    else:\n",
    "        sep = \"\\t\"\n",
    "    print(f'{col}: {sep}{len(bike_rental_df[col].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rental_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove instant, dteday, casual and registered columns.\n",
    "\n",
    "columns_to_keep = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
    "\n",
    "bike_rental_reduced_df = bike_rental_df[columns_to_keep].copy()\n",
    "bike_rental_reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the cnt column, our targets. Anything that looks odd?\n",
    "\n",
    "plt.hist(bike_rental_reduced_df['cnt'], bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a lot of hours have very few rentals. That makes sense, and would probably make up a majority of the nighttime hours. Nothing too odd here, I think.\n",
    "\n",
    "I'll go on and plot the other columns. The continuous ones as scatterplots and the categorical ones as countplots just to see how the number of records vary. Then I'll put boxplots next to both kinds of plots to see the distribution (even if this might make less sense for the continuous features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for the two types of plotting.\n",
    "\n",
    "def plot_features_against_cnt_continuous(feature):\n",
    "    print(f\"________________________________________ {feature} ________________________________________\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    X, y = bike_rental_reduced_df[feature], bike_rental_reduced_df[\"cnt\"]\n",
    "    plt.scatter(X, y)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Number of rentals')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=bike_rental_reduced_df, x=feature, y=\"cnt\", color=\"lightblue\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Value distribution, number of rentals')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_features_against_cnt_categories(feature):\n",
    "    print(f\"________________________________________ {feature} ________________________________________\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(data=bike_rental_reduced_df, x=feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Number of records')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=bike_rental_reduced_df, x=feature, y=\"cnt\", color=\"lightblue\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Value distribution, number of rentals')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plotting functions to the features.\n",
    "\n",
    "continuous_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "for col in continuous_cols:\n",
    "    plot_features_against_cnt_continuous(col)\n",
    "\n",
    "categorical_cols = ['yr', 'mnth', 'hr', 'season', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "for col in categorical_cols:\n",
    "    plot_features_against_cnt_categories(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, even if there's a great spread in the results, atleast we can see that there is a general trend that higher temp and atemp means more rentals, though atleast for temp it seems to dip a bit at very high temperatures (could be 2nd order). There's a declining trend in rentals as it gets more humid and more windy. \n",
    "\n",
    "There are seasonal differences, with more rentals in the summer months (and late spring/early autumn) and the number of rentals seem to have increased from year 2011 to year 2012.\n",
    "\n",
    "There are distinct peaks for commute hours. Naturally, nighttime sees fewer rentals. \n",
    "\n",
    "Weather seems to be a good indicator. Not sure whether to treat weathersit as nominal or ordinal. It gets worse as the numbers increase. But are they comparable. I'll treat them as nominal for now.\n",
    "\n",
    "Now, can and should we keep all these features? If so we need to do one-hot encoding for the categorical data that is not already binary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that seem to be most relevant for predicting the number of rentals are:\n",
    "* temp\n",
    "* atemp\n",
    "* humidity\n",
    "* windspeed\n",
    "* hr\n",
    "* season \n",
    "* workingday\n",
    "* holiday\n",
    "* weathersit\n",
    "* yr\n",
    "\n",
    "I decided to keep workingday, though it is really just a combination of weekday and holiday, and remove weekday. This is to reduce the number of dimensions. Though that means that holiday is represented in two of the features. Not sure if that matters.\n",
    "\n",
    "I also decided to remove month and keep season in order to reduce the number of dimensions.\n",
    "\n",
    "Out of these, the first four are continuous. \n",
    "\n",
    "Holiday, workingday and yr are actually binary, already with either 1 or 0 as values. So these we can keep as is. \n",
    "\n",
    "Season and weathersit have categories looking like numbers. We need to do one-hot encoding for these.\n",
    "\n",
    "What about hr? Does it make sense to treat hour as continuous? Then how do we compare hour 23 to hour 0? So ... no.\n",
    "\n",
    "Also 24 columns will not do. I think it would be better to categorize hr into \"time of day\". Do these need to be of equal size (representing equal numbers of hours)? Not sure. Looking at the data, it would make more sense to have them as \"night\", \"commute hours\", \"daytime\", \"evening\". But they would not be of equal number of hours. I'll go ahead and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure about this. The other way to do it would be to divide 24 hours into equal chunks of time: \n",
    "# night, morning, day, evening.\n",
    "\n",
    "def get_time_of_day(hour):\n",
    "    if hour < 7:\n",
    "        time_of_day = \"night\";\n",
    "    elif hour < 9:\n",
    "        time_of_day = \"commute\"\n",
    "    elif hour < 17:\n",
    "        time_of_day = \"daytime\"\n",
    "    elif hour < 20:\n",
    "        time_of_day = \"commute\"\n",
    "    else:\n",
    "        time_of_day = \"evening\"\n",
    "    return time_of_day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rental_reduced_df.loc[:, \"time_of_day\"] = bike_rental_reduced_df['hr'].apply(get_time_of_day)\n",
    "\n",
    "bike_rental_reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the plots for the new time of day column.\n",
    "plot_features_against_cnt_categories(\"time_of_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_to_keep = ['yr', 'holiday', 'workingday', 'temp', 'atemp',\n",
    "       'hum', 'windspeed', 'season', 'weathersit', 'time_of_day', 'cnt']\n",
    "\n",
    "bike_rental_twice_reduced_df = bike_rental_reduced_df[final_columns_to_keep].copy()\n",
    "\n",
    "bike_rental_twice_reduced_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do one hot encoding on season, weathersit and time_of_day\n",
    "bike_rental_onehot_df = pd.get_dummies(bike_rental_twice_reduced_df, columns=['season', 'weathersit', 'time_of_day'], dtype=int, drop_first=True)\n",
    "\n",
    "bike_rental_onehot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bike_rental_onehot_df.drop(columns=['cnt']).values, bike_rental_onehot_df['cnt'].values\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_rental_onehot_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # set a random state, so we can reproduce our results\n",
    "\n",
    "print('Train set:')\n",
    "print('X:', len(X_train))\n",
    "print('y:', len(y_train), end='\\n\\n')\n",
    "\n",
    "print('Test set:')\n",
    "print('X:', len(X_test))\n",
    "print('y:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression() \n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the weights of the trained model\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for both the train and test set\n",
    "\n",
    "y_train_hat = lr.predict(X_train)\n",
    "y_test_hat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE for both sets\n",
    "\n",
    "print('Train:')\n",
    "print(f'MSE: {mean_squared_error(y_train, y_train_hat)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_train, y_train_hat))}')\n",
    "\n",
    "print('Test:')\n",
    "print(f'MSE: {mean_squared_error(y_test, y_test_hat)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_test_hat))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit of error analysis. Is the above result good or bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot our predictions against the actual values\n",
    "\n",
    "plt.plot(y_test, y_test_hat, 'o');\n",
    "plt.xlabel('Actual'); \n",
    "plt.ylabel('Predicted'); \n",
    "plt.title('Actual vs Predicted');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from looking at the above plot to understand strengths and weaknesses of your model (we can see that our model seem to perform poorly on actual valeus that are either very low, or very high) we can also create stratas of our test_set and plot only the results for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa. That's huge. I guess it's positive that it's actually lower for the test data. But let's go back and adjust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing possible feature combinations to try\n",
    "\n",
    "# Focus on date and time features\n",
    "features_try_1 = ['holiday', 'workingday', 'season_2', 'season_3', 'season_4', 'time_of_day_daytime',\n",
    "       'time_of_day_evening', 'time_of_day_night']\n",
    "\n",
    "# Focus on weather features\n",
    "features_try_2 = ['temp', 'atemp', 'hum', 'windspeed', 'weathersit_2',\n",
    "       'weathersit_3', 'weathersit_4']\n",
    "\n",
    "# Focus on my own idea of what should matter the most (okay most features are kept here...)\n",
    "features_try_3 = ['holiday', 'workingday', 'temp', 'hum', 'windspeed',\n",
    "       'season_2', 'season_3', 'season_4', 'weathersit_2',\n",
    "       'weathersit_3', 'weathersit_4', 'time_of_day_daytime',\n",
    "       'time_of_day_evening', 'time_of_day_night']\n",
    "\n",
    "# Try another balance, perhaps we're including things like humidity and windspeed twice when \n",
    "# applying them along with weathersit?\n",
    "features_try_4 = ['yr', 'workingday', 'temp', 'hum', 'windspeed', 'time_of_day_daytime',\n",
    "       'time_of_day_evening', 'time_of_day_night']\n",
    "\n",
    "# The other way around, excluding hum and windspeed but keeping weathersit\n",
    "features_try_5 = ['yr', 'workingday', 'season_2', 'season_3', 'season_4', 'weathersit_2',\n",
    "       'weathersit_3', 'weathersit_4', 'time_of_day_daytime',\n",
    "       'time_of_day_evening', 'time_of_day_night']\n",
    "\n",
    "for featureset in [features_try_1, features_try_2, features_try_3, features_try_4, features_try_5]:\n",
    "    \n",
    "    print(f\"Trying: {featureset}\\n\")\n",
    "\n",
    "    X, y = bike_rental_onehot_df[featureset].values, bike_rental_onehot_df['cnt'].values\n",
    "\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # set a random state, so we can reproduce our results\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Intercept: {lr.intercept_}\")\n",
    "    print(f\"Coef: {lr.coef_}\")\n",
    "\n",
    "    y_train_hat = lr.predict(X_train)\n",
    "    y_test_hat = lr.predict(X_test)\n",
    "\n",
    "    print('\\nTrain:')\n",
    "    print(f'MSE: {mean_squared_error(y_train, y_train_hat)}')\n",
    "    print(f'RMSE: {np.sqrt(mean_squared_error(y_train, y_train_hat))}')\n",
    "    \n",
    "    print('\\nTest:')\n",
    "    print(f'MSE: {mean_squared_error(y_test, y_test_hat)}')\n",
    "    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_test_hat))}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all my attempts to reduce the number of features of this model resulted in worse results. \n",
    "\n",
    "I guess it's just not possible to get a better fit on a linear model, or I haven't found the optimal set of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
