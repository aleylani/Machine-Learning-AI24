{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d9e76",
   "metadata": {},
   "source": [
    "**Objective and goal for this lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca903507",
   "metadata": {},
   "source": [
    "For this lab, we're going to see how we can transform images to a format we're used to working with, and can thus use for training classification (or regression) models.\n",
    "\n",
    "We will be using the MNIST-dataset, which is a famous dataset of handwritten black & white digits between 0-9. Our goal will be to train a classifier to correctly classify each image as the digit it portrays.\n",
    "\n",
    "You can read more about MNIST [here](https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50fda6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dc3c8",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae426fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        return np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num = struct.unpack(\">II\", f.read(8))\n",
    "        return np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "# Load training data\n",
    "train_images = load_mnist_images(\"../data/mnist/train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"../data/mnist/train-labels.idx1-ubyte\")\n",
    "\n",
    "# Load test data\n",
    "test_images = load_mnist_images(\"../data/mnist/t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"../data/mnist/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce9ada",
   "metadata": {},
   "source": [
    "Let's investigate what we just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_images shape :', train_images.shape)\n",
    "print('test_images shape  :', test_images.shape, end='\\n\\n')\n",
    "\n",
    "print('train_labels shape :', train_labels.shape)\n",
    "print('test_labels shape  :', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db896dd",
   "metadata": {},
   "source": [
    "So both train and test images are 3D-arrays. Let's pick the first item in train_images and investigate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_images[0] :', train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5902193",
   "metadata": {},
   "source": [
    "So, the first (out of 60.000) items in train_images is a 28x28 array. Actually, it's an image of size 28x28 pixels.\n",
    "\n",
    "We can visualise this easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa569ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0], cmap='gray');\n",
    "plt.title(f'Label: {train_labels[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56994c46",
   "metadata": {},
   "source": [
    "As you might've noticed, the train_labels contain the true labels (i.e., the targets) for each handwritten image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9a0ed",
   "metadata": {},
   "source": [
    "Let's plot some more images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "number_of_images = 10\n",
    "\n",
    "indices = random.sample(range(60000), number_of_images)\n",
    "\n",
    "fig, axes = plt.subplots(1, number_of_images, figsize=(15, 3))\n",
    "\n",
    "for idx, ax in zip(indices, axes):\n",
    "    ax.imshow(train_images[idx], cmap='gray')\n",
    "    ax.set_title(f'Label: {train_labels[idx]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc678f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cd1bb",
   "metadata": {},
   "source": [
    "Ok, so how do we transform this data into a format that we can train the models we've learnt about thus far? \n",
    "\n",
    "Well,  what we'll do is that we're going to use *every pixel as it's own feature*. Since each image is 28x28 pixels, we're going to have 28x28 = 784 features for each image.\n",
    "\n",
    "We can use flatten() to transform a 2D (28,28) shaped array to a single 1D (784) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494dcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy transformation\n",
    "\n",
    "train_images[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do it for all the images in the train_images\n",
    "\n",
    "train_images_flattened = [list(image.flatten()) for image in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd534722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_flattened_array = np.array([image.flatten() for image in train_images])\n",
    "\n",
    "# transform that list to a dataframe so that we can see what's going on\n",
    "X_train_val = pd.DataFrame(train_images_flattened_array)\n",
    "\n",
    "X_train_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7240f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might aswell make the labels into a dataframe too\n",
    "\n",
    "y_train_val = pd.DataFrame(train_labels)\n",
    "\n",
    "y_train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652eeedd",
   "metadata": {},
   "source": [
    "Cool, no we're on familiar ground! We have our X_train_val (features) and y_train_val (targets) in a suitable format.\n",
    "\n",
    "Now we can try training some multiclass classification models on this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84120a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fe82d",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cdda2",
   "metadata": {},
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c445c8",
   "metadata": {},
   "source": [
    "Transform test_images and test_labels similarly as above, and save them as X_test and y_test.\n",
    "\n",
    "This is the test set you will use at the end, to assess final performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0824553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e479ab",
   "metadata": {},
   "source": [
    "**Task 1.5 (bonus**)\n",
    "\n",
    "Let's normalize our features! Because why not. It won't hurt the algorithms that don't require it - and we might aswell show how easily images can be scaled properly.\n",
    "\n",
    "In the case for gray-scale images, we simply divide all features (pixels) by 255. Why? Because that's the maximum possible value. This will bring all grayscale values to the range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56db7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = X_train_val/255\n",
    "\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63c908",
   "metadata": {},
   "source": [
    "Awesome. Done. Feel free to check that all grayscale values are properly scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38df6c5",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Using all 784 features (no additional feature engineering or manipulation needed), start training and GridSearching for the best performing hyperparameters for \n",
    "\n",
    "KNN, DecisionTree, RandomForest, AdaBoost (chose yourself which base estimator to use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0441a",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "When you have the best performing hyperparameters, do an ordinary train/validation split on X_train_val and y_train_val.\n",
    "\n",
    "Train the models with their respective best performing hyperparameters on X_train and then evaluate performance on X_val.\n",
    "\n",
    "In particular, make good use of confusion matrices here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03488f04",
   "metadata": {},
   "source": [
    "**Task 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99670e",
   "metadata": {},
   "source": [
    "For the models you've trained in Task 3, try plotting the validation samples they classified **incorrectly**. As the title for each image, write the true label and the predicted label.\n",
    "\n",
    "Do the mistakes kinda make sense? Can you forgive your models? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ffbdb",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "\n",
    "For each model with the identified best performing hyperparameters, do a full training on X_train_val - then assess performance on X_test.\n",
    "\n",
    "Which model did you find to perform worst/best? Is the difference large?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf94bc4",
   "metadata": {},
   "source": [
    "**Task 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cd099",
   "metadata": {},
   "source": [
    "If you feel frisky, you can try a tad more difficult problem. Try loading and training on the [Fashion MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist) dataset instead. \n",
    "\n",
    "It's a relatively more difficult dataset to classify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
