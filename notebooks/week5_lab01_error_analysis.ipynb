{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis in Machine Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore **Error Analysis** in Machine Learning. Many beginners stop at evaluating a model with overall metrics like accuracy, precision, and recall. \n",
    "\n",
    "However, these metrics alone are often **not enough** to fully understand the modelâ€™s strengths and weaknesses.\n",
    "\n",
    "### Why Error Analysis?\n",
    "\n",
    "Imagine you build a model that predicts whether passengers on the Titanic survived. \n",
    "\n",
    "You train it, evaluate it, and achieve an accuracy of 80%. That seems like a great result! But what if we look deeper?\n",
    "\n",
    "- Did the model perform equally well for **men and women**?\n",
    "- What about **children versus adults**?\n",
    "- Did it struggle more with **certain passenger classes**?\n",
    "\n",
    "Overall performance metrics **hide critical weaknesses**. A model that performs well on average may still make **systematic errors** on important subgroups. \n",
    "\n",
    "If these errors affect certain groups more than others, the model may reinforce biases and lead to unfair or unreliable decisions.\n",
    "\n",
    "### What is Error Analysis?\n",
    "\n",
    "Error Analysis helps us:\n",
    "- Identify subgroups where the model performs poorly\n",
    "- Diagnose biases or unfairness in predictions\n",
    "- Gain insights to improve model performance in targeted ways\n",
    "- Detect situations where the model **fails consistently**\n",
    "\n",
    "Instead of just looking at overall performance, we **slice** our dataset into different subsets and analyze performance within each. This allows us to find hidden weaknesses and understand **why** the model makes mistakes.\n",
    "\n",
    "### Real-World Importance of Error Analysis\n",
    "\n",
    "Error Analysis is critical in **high-stakes applications** like:\n",
    "- **Healthcare:** A diagnostic AI system might perform well overall but fail to detect certain diseases in specific demographics.\n",
    "- **Finance:** A credit approval model may systematically reject applicants from certain backgrounds due to biases in training data.\n",
    "- **Autonomous Vehicles:** A self-driving car model may struggle with detecting pedestrians at night compared to daylight conditions.\n",
    "\n",
    "In short, **Error Analysis bridges the gap between high-level performance metrics and real-world usability**, making models not just accurate but also **fair, reliable, and trustworthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load a simple binary classification dataset (e.g., The Titanic Dataset)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mload_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Load a simple binary classification dataset (e.g., The Titanic Dataset)\n",
    "\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "We will be very brief and *sloppy* with our feature engineering and data prep here - although important, it's not the point of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=[\"survived\"])\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embark_town'] = df['embark_town'].astype('category').cat.codes\n",
    "df['class'] = df['class'].astype('category').cat.codes\n",
    "df['who'] = df['who'].astype('category').cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "features = ['pclass', 'sex', 'age', 'fare', 'sibsp', 'parch']\n",
    "X = df[features]\n",
    "y = df['survived']\n",
    "\n",
    "# Drop rows with missing values in features\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Overall Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Now, let's go beyond these overall metrics and analyze **performance across different subgroups**. \n",
    "We will analyze how well the model performs across age groups.\n",
    "\n",
    "### Performance Across Age Groups\n",
    "\n",
    "We will here demonstrate how to split the test set into different age groups and compute accuracy, precision, and recall for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins\n",
    "age_bins = [0, 18, 40, 60, 100]\n",
    "age_labels = ['0-18', '19-40', '41-60', '60+']\n",
    "X_test['age_group'] = pd.cut(X_test['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Compute metrics per age group\n",
    "for age_group in age_labels:\n",
    "    subset = X_test[X_test['age_group'] == age_group]\n",
    "    y_true_subset = y_test.loc[subset.index]\n",
    "    y_pred_series = pd.Series(y_pred, index=X_test.index)  # Ensure aligned indices\n",
    "    y_pred_subset = y_pred_series.loc[subset.index]\n",
    "    \n",
    "    acc = accuracy_score(y_true_subset, y_pred_subset)\n",
    "    prec = precision_score(y_true_subset, y_pred_subset, zero_division=0)\n",
    "    rec = recall_score(y_true_subset, y_pred_subset, zero_division=0)\n",
    "    \n",
    "    print(f\"Performance for Age Group {age_group}:\")\n",
    "    print(f\"  Accuracy: {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall: {rec:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can now identify which age groups perform worse. \n",
    "If certain subgroups perform poorly, we can:\n",
    "- Collect more data from those groups\n",
    "- Try different model architectures\n",
    "- Adjust loss functions to handle class imbalances better\n",
    "\n",
    "This is how **Error Analysis** helps improve machine learning models beyond just looking at overall accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
